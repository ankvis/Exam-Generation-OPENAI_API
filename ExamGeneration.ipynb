{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tell GPT how to generate the test\n",
    "\n",
    "Creating a multiple choice quiz. The user needs to provide topic, number of multiple choices and total number of questions to be asked from the end user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(topic, num_questions, num_possible_answers):\n",
    "    prompt = f\"Create a multiple choice quiz on the topic of {topic} consisting of {num_questions}. \" \\\n",
    "    +f\"Each question should have {num_possible_answers} options. \" \\\n",
    "    +f\"Also include the correct answer for each question using the starting string 'Correct Answer:'\"\n",
    "\n",
    "    return prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Create a multiple choice quiz on the topic of Python consisting of 4. Each question should have 4 options. Also include the correct answer for each question using the starting string 'Correct Answer:'\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_test_prompt(\"Python\", 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API Call\n",
    "Using text-davinci-003 for normal text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine ='text-davinci-003',\n",
    "    prompt=create_test_prompt('US history', 4,4),\n",
    "    max_tokens=256,\n",
    "    temperature = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q1. Who was the first president of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. Abraham Lincoln\n",
      "Correct Answer: A. George Washington\n",
      "\n",
      "Q2. What year was the Declaration of Independence signed?\n",
      "A. 1776\n",
      "B. 1787\n",
      "C. 1789\n",
      "D. 1791\n",
      "Correct Answer: A. 1776\n",
      "\n",
      "Q3. What was the name of the first successful English settlement in the Americas?\n",
      "A. Jamestown\n",
      "B. Plymouth\n",
      "C. New York\n",
      "D. Boston\n",
      "Correct Answer: A. Jamestown\n",
      "\n",
      "Q4. What is the name of the current president of the United States?\n",
      "A. Donald Trump\n",
      "B. Barack Obama\n",
      "C. George W. Bush\n",
      "D. Bill Clinton\n",
      "Correct Answer: A. Donald Trump\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q/A Extraction\n",
    "\n",
    "We now need to extract the questions and answers to present them to the students later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_view(test, num_questions):\n",
    "    student_view = {1:''}\n",
    "    question_number = 1\n",
    "    for line in test.split(\"\\n\"):\n",
    "        if not line.startswith(\"Correct Answer:\"):\n",
    "            student_view[question_number] +=line+'\\n'\n",
    "        else:\n",
    "            if question_number < num_questions:\n",
    "                question_number +=1\n",
    "                student_view[question_number] =''\n",
    "    return student_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '\\n\\nQ1. Who was the first president of the United States?\\nA. George Washington\\nB. Thomas Jefferson\\nC. John Adams\\nD. Abraham Lincoln\\n',\n",
       " 2: '\\nQ2. What year was the Declaration of Independence signed?\\nA. 1776\\nB. 1787\\nC. 1789\\nD. 1791\\n',\n",
       " 3: '\\nQ3. What was the name of the first successful English settlement in the Americas?\\nA. Jamestown\\nB. Plymouth\\nC. New York\\nD. Boston\\n',\n",
       " 4: '\\nQ4. What is the name of the current president of the United States?\\nA. Donald Trump\\nB. Barack Obama\\nC. George W. Bush\\nD. Bill Clinton\\n'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_student_view(response['choices'][0]['text'],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_student_view(response['choices'][0]['text'],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q1. Who was the first president of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. Abraham Lincoln\n",
      "\n",
      "\n",
      "Q2. What year was the Declaration of Independence signed?\n",
      "A. 1776\n",
      "B. 1787\n",
      "C. 1789\n",
      "D. 1791\n",
      "\n",
      "\n",
      "Q3. What was the name of the first successful English settlement in the Americas?\n",
      "A. Jamestown\n",
      "B. Plymouth\n",
      "C. New York\n",
      "D. Boston\n",
      "\n",
      "\n",
      "Q4. What is the name of the current president of the United States?\n",
      "A. Donald Trump\n",
      "B. Barack Obama\n",
      "C. George W. Bush\n",
      "D. Bill Clinton\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in result:\n",
    "    print(result[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(test, num_questions):\n",
    "    answers = {1:''}\n",
    "    question_number = 1\n",
    "    for line in test.split('\\n'):\n",
    "        if line.startswith('Correct Answer:'):\n",
    "            answers[question_number] +=line+'\\n'\n",
    "\n",
    "            if question_number < num_questions:\n",
    "                question_number +=1\n",
    "                answers[question_number] = ''\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Correct Answer: A. George Washington\\n',\n",
       " 2: 'Correct Answer: A. 1776\\n',\n",
       " 3: 'Correct Answer: A. Jamestown\\n',\n",
       " 4: 'Correct Answer: A. Donald Trump\\n'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer(response['choices'][0]['text'],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_view = create_student_view(response['choices'][0]['text'],4)\n",
    "answers = extract_answer(response['choices'][0]['text'],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exam simulation\n",
    "Based on the extracted questions, we can now simulate the exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the exam \n",
    "def take(student_view):\n",
    "    student_answers = {}\n",
    "    for question, question_view in student_view.items():\n",
    "        print(question_view)\n",
    "        answer = input(\"Enter your answer: \")\n",
    "        student_answers[question] = answer\n",
    "    return student_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q1. Who was the first president of the United States?\n",
      "A. George Washington\n",
      "B. Thomas Jefferson\n",
      "C. John Adams\n",
      "D. Abraham Lincoln\n",
      "\n",
      "\n",
      "Q2. What year was the Declaration of Independence signed?\n",
      "A. 1776\n",
      "B. 1787\n",
      "C. 1789\n",
      "D. 1791\n",
      "\n",
      "\n",
      "Q3. What was the name of the first successful English settlement in the Americas?\n",
      "A. Jamestown\n",
      "B. Plymouth\n",
      "C. New York\n",
      "D. Boston\n",
      "\n",
      "\n",
      "Q4. What is the name of the current president of the United States?\n",
      "A. Donald Trump\n",
      "B. Barack Obama\n",
      "C. George W. Bush\n",
      "D. Bill Clinton\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_answers = take(student_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a', 2: 'b', 3: 'v', 4: 'd'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Correct Answer: A. George Washington\\n',\n",
       " 2: 'Correct Answer: A. 1776\\n',\n",
       " 3: 'Correct Answer: A. Jamestown\\n',\n",
       " 4: 'Correct Answer: A. Donald Trump\\n'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Grading\n",
    "Based on the student's answers and correct answers, we can now grade the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(correct_answer_dict, student_answers):\n",
    "    correct_answers = 0\n",
    "    for question, answer in student_answers.items():\n",
    "        if answer.upper == correct_answer_dict[question][16]:\n",
    "            correct_answers += 1\n",
    "    grade = 100*correct_answers / len(answers)\n",
    "\n",
    "    if grade <60:\n",
    "        passed = \"Failed\"\n",
    "    else:\n",
    "        passed = \"Pass\"\n",
    "    \n",
    "    return f\"{correct_answers} / {len(answers)} correct! You got {grade} grade, You {passed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 / 4 correct! You got 0.0 grade, You Failed'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade(answers, student_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
